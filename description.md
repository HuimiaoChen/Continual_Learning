# Continual (incremental) learning for 3D image segmentation

The ability to dynamically extend a model to new data and classes is critical for multiple organ and tumor segmentation. However, due to privacy regulations, accessing previous data and annotations can be problematic in the medical domain. This poses a significant obstacle to preserving the high segmentation accuracy of the old classes when learning from new data and new classes, due to the catastrophic forgetting phenomenon. In this paper, we first empirically demonstrate that simply using pseudo labels can fairly mitigate this problem in the setting of abdominal organ segmentation. In addition, we propose a novel network design for continual organ and tumor segmentation that introduces little computational overhead.

Specifically, we propose to use a set of lightweight organ-specific heads to replace a traditional output layer. Each head is matched to a specific class, thus flexible to extend to new coming classes. The heads allow independent probability prediction for newly introduced and previously learned classes, therefore minimizing the impact of new classes on old ones during continual learning. In addition, we propose to introduce CLIP embeddings to the organ-specific heads, which encode semantic information of each class through large-scale image-text co-training.

The proposed method is evaluated on both in-house and public abdominal CT datasets under organ and tumor segmentation tasks. Empirical results suggest that the proposed design improves the segmentation performance of a baseline neural network on newly-introduced and previously-learned classes along the learning trajectory.